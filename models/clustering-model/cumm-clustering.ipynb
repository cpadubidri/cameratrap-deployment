{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_geojson(filename, output_geojson, n_clusters=10):\n",
    "    # for i in range(0,n_clusters):\n",
    "    geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "    }\n",
    "    with open(filename, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # print(int(row['cluster']))\n",
    "            # if int(row['cluster'])==i:\n",
    "            feature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Point\",\n",
    "                    \"coordinates\": [float(row['lon']), float(row['lat'])]\n",
    "                },\n",
    "                \"properties\": {\n",
    "                    \"label\": row['label'],\n",
    "                    # \"PC1\": float(row['PC1']),\n",
    "                    # \"PC2\": float(row['PC2']),\n",
    "                    # \"PC3\": float(row['PC3']),\n",
    "                    \"cluster\": int(row['cluster']),\n",
    "                    # \"path\": row['path']\n",
    "                }\n",
    "            }\n",
    "            geojson[\"features\"].append(feature)\n",
    "                # break\n",
    "        geojson_file_path = output_geojson\n",
    "        # print(geojson_file_path)\n",
    "\n",
    "        with open(geojson_file_path, 'w', encoding='utf-8') as geojsonfile:\n",
    "            json.dump(geojson, geojsonfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(embeddings, n_components=20,start_component=5):\n",
    "    pca = PCA(n_components)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    print(f'Variance {pca.explained_variance_ratio_}')\n",
    "    print(f'Variance {pca.explained_variance_ratio_[start_component:].sum()}')\n",
    "\n",
    "\n",
    "    return reduced_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clustering(embeddings, labels, lat, lon, n_clusters, filename):\n",
    "    print(embeddings.shape)\n",
    "    print(\"K-Mean in process\")\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    'label': labels,\n",
    "    'cluster': clusters,\n",
    "    'lat': lat,\n",
    "    'lon':lon\n",
    "    })\n",
    "\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4864 (4864, 32)\n",
      "4890 (4864, 512)\n",
      "(4864, 544)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def convert_to_list(embedding_str):\n",
    "    return ast.literal_eval(embedding_str)\n",
    "\n",
    "\n",
    "filename1=f'data/weather-embedding.csv'\n",
    "data1 = pd.read_csv(filename1)\n",
    "data1['embedding'] = data1['embedding'].apply(convert_to_list)\n",
    "embeddings1 = np.array(data1['embedding'].tolist())\n",
    "labels = data1['cell-id'].values\n",
    "print(len(labels), (embeddings1.shape))\n",
    "\n",
    "\n",
    "filename2=f'data/elevation-crops-embedding.csv'\n",
    "data2 = pd.read_csv(filename2)\n",
    "data2_fil = data2[data2['cell-id'].isin(labels)].copy()  \n",
    "\n",
    "data2_fil['embedding'] = data2_fil['embedding'].apply(convert_to_list)\n",
    "embeddings2 = np.array(data2_fil['embedding'].tolist())\n",
    "print(len(data2), (embeddings2.shape))\n",
    "\n",
    "filename3=f'data/.csv'\n",
    "data3 = pd.read_csv(filename3)\n",
    "data3_fil = data3[data3['cell-id'].isin(labels)].copy()  \n",
    "\n",
    "data3_fil['embedding'] = data3_fil['embedding'].apply(convert_to_list)\n",
    "embeddings3 = np.array(data3_fil['embedding'].tolist())\n",
    "print(len(data3), (embeddings3.shape))\n",
    "\n",
    "\n",
    "concat_embeddings = np.concatenate((embeddings1, embeddings2, embeddings2), axis=1)\n",
    "print(concat_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply PCA if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance [0.52566341 0.09806223 0.08015789 0.03286504 0.02897634 0.02729958\n",
      " 0.02600662 0.02173407 0.01989275 0.01695706 0.01484541 0.01280482\n",
      " 0.01256415 0.01088958 0.00901266 0.00758065]\n",
      "Variance 0.17958734211385247\n"
     ]
    }
   ],
   "source": [
    "n_components=16  # PCA components\n",
    "reduced_embeddings = apply_pca(concat_embeddings, n_components=n_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_data = pd.read_csv('data/location.csv')\n",
    "coord_data_sub = coord_data[coord_data['cell-id'].isin(labels)]\n",
    "\n",
    "lat = coord_data_sub['lat']\n",
    "lon = coord_data_sub['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4864, 544)\n",
      "K-Mean in process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/savvas/anaconda3/envs/PyTorch/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_geojson = '/home/savvas/SUPER-NAS/USERS/Chirag/TEMP-Folder/emb-cluster/cumm-cluter.geojson'\n",
    "n_clusters = 7 \n",
    "\n",
    "apply_clustering(concat_embeddings, labels=labels, lat=lat, lon=lon, n_clusters=n_clusters, filename='cumm-cluster.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='cumm-cluster.csv'\n",
    "csv_to_geojson(filename,output_geojson, n_clusters=n_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
